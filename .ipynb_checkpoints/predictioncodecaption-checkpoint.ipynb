{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bd2d7ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "from keras_retinanet.utils.gpu import setup_gpu\n",
    "\n",
    "# import miscellaneous modules\n",
    "\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "pATHTEST='/home/greenbaum-gpu/Reuben/keras-retinanet'\n",
    "testnames, testpaths = listFile(pATHTEST, '.tif')\n",
    "all_detections = [[None for i in range(num_class)] for j in range(len(testnames))]\n",
    "clean_detections = [[None for i in range(num_class)] for j in range(len(testnames))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "852429c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cHANNELS = {'561nm':'RFP', '640nm':'GFP'}\n",
    "\n",
    "# print(model.summary())\n",
    "# labels_to_names = {0: 'class 0', 1: 'class 1', 2: 'class 2', ...}, e.g.\n",
    "labels_to_names = {0: 'uncertain', 1: 'yellow neuron', 2: 'yellow astrocyte', \n",
    "                    3: 'green neuron', 4: 'green astrocyte', 5: 'red neuron', \n",
    "                    6: 'red astrocyte'}\n",
    "\n",
    "tHRESHOLD = 0.5 # threshold for detection confidence score\n",
    "sAVEIMAGE = True # whether to export image with detection boxes\n",
    "cAPTION = False # whether to export image with label captions\n",
    "sAVECSV = True # whether to export table of detections\n",
    "sTARTID = None; eNDID = None # start and end of tile indexes for prediction; if None, all tiles\n",
    "tiles = [1] # list of selected tile indexes for prediction; if empty, sTARTID:eNDID\n",
    "mERGEZTILE = True # whether to merge predictions across z for a single tile\n",
    "mERGEZ = False # whether to merge predictions across z during stitching\n",
    "rES = [[0.65, 0.65, 10]] # voxel size of the dataset\n",
    "tILESIZE = 2048 # size of a field of view (tile)\n",
    "xsize = 512; ysize = 512; step = 448 # size and step of image patches for detection\n",
    "classes = list(labels_to_names.values())\n",
    "num_class = len(classes)\n",
    "sUFFIX = [\".png\",\"_cap.png\"] # image file suffix when save w/ or w/o caption\n",
    "channels = list(cHANNELS.keys()); markers = list(cHANNELS.values())\n",
    "aLIGNED='None'\n",
    "\n",
    "model_path = os.path.join('snapshots', \n",
    "                          'trainedmodel.h5')\n",
    "\n",
    "# load retinanet model\n",
    "model = models.load_model(model_path, backbone_name='resnet50')\n",
    "\n",
    "# if the model is not converted to an inference model, use the line below\n",
    "# see: https://github.com/fizyr/keras-retinanet#converting-a-training-model-to-inference-model\n",
    "model = models.convert_model(model)\n",
    "# Initialize count for relevant classes only (1 to 6).\n",
    "count = np.zeros((1, 6), dtype=int)  # Only track counts for classes 1 to 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aaa1818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Functions\n",
    "\n",
    "def listFile(path, ext):\n",
    "    \n",
    "    '''    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : string\n",
    "        Directory of processing images. \n",
    "    ext : string\n",
    "        Desired file extention.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A list of all files with specific extension in a directory (including subdirectory).\n",
    "\n",
    "    '''\n",
    "\n",
    "    filename_list, filepath_list = [], []\n",
    "    # r = root, d = directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for filename in f:\n",
    "            if ext in filename:\n",
    "                filename_list.append(filename)\n",
    "                filepath_list.append(os.path.join(r, filename))\n",
    "    return sorted(filename_list), sorted(filepath_list)\n",
    "\n",
    "def listTile(path):\n",
    "    # Return a list of dir of tiles\n",
    "    \n",
    "    dir_list = []\n",
    "    dirname_list = []\n",
    "    for r, d, f in os.walk(path):\n",
    "        if not d:\n",
    "            dir_list.append(r)\n",
    "            dirname_list.append(os.path.basename(r))\n",
    "    return sorted(dirname_list), sorted(dir_list)\n",
    "\n",
    "def mapTile(dirname_list, left2right=True, top2bottom=True):\n",
    "    # Return a dictionary\n",
    "    # key: tile dir name\n",
    "    # value: tile position (y_index, x_index)\n",
    "    y_pos = []; x_pos = []\n",
    "    for dirname in dirnames:\n",
    "        if dirname[:6] not in y_pos:\n",
    "            y_pos.append(dirname[:6])\n",
    "        if dirname[-6:] not in x_pos:\n",
    "            x_pos.append(dirname[-6:])\n",
    "    # Reverse direction\n",
    "    if not left2right:\n",
    "        x_pos.sort(reverse=True)\n",
    "    if not top2bottom:\n",
    "        y_pos.sort(reverse=True)\n",
    "    dir_map = {}\n",
    "    for dirname in dirnames:\n",
    "        dir_map[dirname] = (y_pos.index(dirname[:6]), x_pos.index(dirname[-6:]))\n",
    "    return dir_map\n",
    "\n",
    "def non_max_suppression_merge(boxes, overlapThresh=0.5, sort=4):\n",
    "    '''\n",
    "    https://www.computervisionblog.com/2011/08/blazing-fast-nmsm-from-exemplar-svm.html\n",
    "    '''\n",
    "    \n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # initialize the list of picked indexes\t\n",
    "    pick = []\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "\t# boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    idxs = np.argsort(boxes[:,sort])\n",
    "\t# keep looping while some indexes still remain in the indexes\n",
    "\t# list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the\n",
    "        # index value to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        # find the largest (x, y) coordinates for the start of\n",
    "\t\t# the bounding box and the smallest (x, y) coordinates\n",
    "        # for the end of the bounding box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\t\t# compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        # expand the picked bounding box\n",
    "        if np.where(overlap > overlapThresh)[0].size > 0:\n",
    "            # find the largest bounding box with overlap\n",
    "            xxx1 = min(x1[i], x1[idxs[np.where(overlap > overlapThresh)[0]]].min())\n",
    "            yyy1 = min(y1[i], y1[idxs[np.where(overlap > overlapThresh)[0]]].min())\n",
    "            xxx2 = max(x2[i], x2[idxs[np.where(overlap > overlapThresh)[0]]].max())\n",
    "            yyy2 = max(y2[i], y2[idxs[np.where(overlap > overlapThresh)[0]]].max())\n",
    "            boxes[i,:4] = [xxx1,yyy1,xxx2,yyy2]\n",
    "            # delete all indexes from the index list that have\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "\t\t\tnp.where(overlap > overlapThresh)[0])))\n",
    "\t# return only the bounding boxes that were picked using the\n",
    "\t# integer data type\n",
    "    return boxes[pick]\n",
    "\n",
    "# for multi-channel detection\n",
    "\n",
    "def stitchDetection(detections, H, W, xsize=512, ysize=512, step=448):\n",
    "    ''' stitch predictions on a single tile image\n",
    "    '''\n",
    "    \n",
    "    # mask_overlap = np.zeros((H,W), dtype=float)\n",
    "    x_overlap = xsize-step; y_overlap = ysize-step\n",
    "    rows = []\n",
    "    for row in range(step,W,step):\n",
    "        rows.extend(list(range(row-32,row+x_overlap+32)))\n",
    "    # mask_overlap[rows] = 1\n",
    "    cols = []\n",
    "    for col in range(step,H,step):\n",
    "        cols.extend(list(range(col-32,col+y_overlap+32)))\n",
    "    # mask_overlap[:,cols] = 1\n",
    "    \n",
    "    overlap_idx = []\n",
    "    for i, detection in enumerate(list(detections)):\n",
    "        box = list(map(int, detection[:-1]))\n",
    "        if (box[0] in rows) or (box[1] in cols):\n",
    "            overlap_idx.append(i)\n",
    "    \n",
    "    overlap_detections = detections[overlap_idx].copy()\n",
    "    clean_mask = np.ones(detections.shape[0], dtype=bool)\n",
    "    clean_mask[overlap_idx] = False\n",
    "    clean_detections = detections[clean_mask].copy()\n",
    "    \n",
    "    if overlap_detections.size > 1:\n",
    "        overlap_detections = non_max_suppression_merge(overlap_detections)\n",
    "        clean_detections = np.append(clean_detections, overlap_detections, \n",
    "                                     axis=0)\n",
    "        \n",
    "    return clean_detections  \n",
    "\n",
    "# for multi-tile stitching\n",
    "\n",
    "def load_predictions(all_predictions, csv_reader, classes, z_start, Z, disp, file_z0 = None):\n",
    "    ''' load predictions from csv\n",
    "    '''\n",
    "    \n",
    "    # csv: img, x1, y1, x2, y2, class, score, average intensity, z\n",
    "    # all_predictions = [[np.empty((0, 7)) for i in range(num_class)] for j in range(n_slices)]\n",
    "    ABS_X, ABS_Y, ABS_Z = disp\n",
    "    z0 = z_start - ABS_Z\n",
    "    z1 = z0 + Z\n",
    "    for row in csv_reader:\n",
    "        img_file, x1, y1, x2, y2, class_name, score, mean, z = row[:9]\n",
    "        z = int(float(z))\n",
    "        if file_z0:\n",
    "            file_z = int(os.path.splitext(img_file)[0].split('_')[-1])\n",
    "            z = (file_z - file_z0)//100 + 1\n",
    "        x1 = float(x1); x2 = float(x2); y1 = float(y1); y2 = float(y2)\n",
    "        score = float(score); mean = float(mean)\n",
    "        if z-1 in range(z0,z1):\n",
    "            x1 += ABS_X\n",
    "            x2 += ABS_X\n",
    "            y1 += ABS_Y\n",
    "            y2 += ABS_Y\n",
    "            z = z - z0\n",
    "            # print(z)\n",
    "            all_predictions[z-1][classes.index(class_name)] = np.concatenate((all_predictions[z-1][classes.index(class_name)],\n",
    "                                                                              [[x1,y1,x2,y2,score,mean,z]]))\n",
    "       \n",
    "    return all_predictions\n",
    "\n",
    "def combine_predictions(all_predictions, csv_reader, classes, z_start, Z, pos, disp_mat, size, tILESIZE = 2048, file_z0 = None):\n",
    "    ''' exclude redundant predictions in overlapped areas for multi-tile stithing\n",
    "        join predictions according to cell type\n",
    "    '''\n",
    "    \n",
    "    # csv: img, x1, y1, x2, y2, class, score, average intensity, z\n",
    "    # all_predictions = [[np.empty((0, 8)) for i in range(2)] for j in range(n_slices)]\n",
    "    row, col = pos\n",
    "    ABS_X, ABS_Y, ABS_Z = disp_mat[pos]\n",
    "    H, W = size\n",
    "    mask = np.zeros((H,W), dtype=float)\n",
    "    if col > 0: \n",
    "        x_pre_start = disp_mat[row,col-1][0]\n",
    "        y_pre_start = disp_mat[row,col-1][1]       \n",
    "        mask[max(ABS_Y,y_pre_start):min(ABS_Y+tILESIZE,y_pre_start+tILESIZE),\n",
    "             max(ABS_X,x_pre_start):min(ABS_X+tILESIZE,x_pre_start+tILESIZE)] = 1\n",
    "    if row > 0:\n",
    "        x_pre_start = disp_mat[row-1,col][0]\n",
    "        y_pre_start = disp_mat[row-1,col][1]       \n",
    "        mask[max(ABS_Y,y_pre_start):min(ABS_Y+tILESIZE,y_pre_start+tILESIZE),\n",
    "             max(ABS_X,x_pre_start):min(ABS_X+tILESIZE,x_pre_start+tILESIZE)] = 1        \n",
    "    z0 = z_start - ABS_Z\n",
    "    z1 = z0 + Z\n",
    "    # print(z0,z1)\n",
    "    for row in csv_reader:\n",
    "        img_file, x1, y1, x2, y2, class_name, score, mean, z = row[:9] # default\n",
    "        # img_file, x1, y1, x2, y2, class_name, score, mean, mean_1, mean_2, z = row[:11]\n",
    "        z = int(float(z))\n",
    "        if file_z0:\n",
    "            file_z = int(os.path.splitext(img_file)[0].split('_')[-1])\n",
    "            z = (file_z - file_z0)//100 + 1\n",
    "        x1 = float(x1); x2 = float(x2); y1 = float(y1); y2 = float(y2)\n",
    "        score = float(score); mean = float(mean)\n",
    "        if z-1 in range(z0,z1):\n",
    "            x1 += ABS_X\n",
    "            x2 += ABS_X\n",
    "            y1 += ABS_Y\n",
    "            y2 += ABS_Y\n",
    "            z = z - z0\n",
    "            # print(z)\n",
    "            if not mask[int((y1+y2)//2),int((x1+x2)//2)] > 0:\n",
    "                # save as neuron/astrocyte\n",
    "                all_predictions[z-1][classes.index(class_name)%2] = np.concatenate((all_predictions[z-1][classes.index(class_name)%2],\n",
    "                                                                                    [[x1,y1,x2,y2,score,mean,classes.index(class_name),z]]))\n",
    "       \n",
    "    return all_predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "456d324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, testpath in enumerate(testpaths):\n",
    "    start = time.time()\n",
    "\n",
    "    fullimg_c1 = read_image_bgr(testpath)\n",
    "    fullimg = np.zeros(fullimg_c1.shape, dtype=np.uint16)\n",
    "    fullimg[:, :, 2] = fullimg_c1[:, :, 1].copy()  # BGR\n",
    "    if aLIGNED == 'Table':\n",
    "        # Translate aligned channel\n",
    "        if (i + z_align_disp) in range(len(testpaths)):\n",
    "            fullimg_c2 = read_image_bgr(testpaths[i + z_align_disp].replace(channels[0], channels[1]))\n",
    "            T = np.float32([[1, 0, xy_align_disp[i, 0]], [0, 1, xy_align_disp[i, 1]]])\n",
    "            fullimg[:, :, 1] = cv2.warpAffine(fullimg_c2[:, :, 1], T, fullimg_c2[:, :, 1].shape)\n",
    "    elif aLIGNED == 'Image':\n",
    "        fullimg_c2 = read_image_bgr(\n",
    "            (testpath.replace(channels[0], 'NM_align\\\\aligned\\\\' + markers[1])).replace('tiff', 'tif')\n",
    "        )\n",
    "        fullimg[:, :, 1] = fullimg_c2[:, :, 1]\n",
    "    else:\n",
    "        fullimg_c2 = read_image_bgr(testpath.replace(channels[0], channels[1]))\n",
    "        fullimg[:, :, 1] = fullimg_c2[:, :, 1]\n",
    "\n",
    "    if (fullimg[:, :, 2].sum() > 0) & (fullimg[:, :, 1].sum() > 0):\n",
    "        fulldraw = fullimg.copy() / 257  # RGB to save\n",
    "        fulldraw = (fulldraw * 8).clip(0, 255)  # Increase brightness\n",
    "\n",
    "        # Padding\n",
    "        H0, W0, _ = fullimg.shape\n",
    "\n",
    "        if not (H0 - ysize) % step == 0:\n",
    "            H = H0 - H0 % step + ysize\n",
    "        else:\n",
    "            H = H0\n",
    "        if not (W0 - xsize) % step == 0:\n",
    "            W = W0 - W0 % step + xsize\n",
    "        else:\n",
    "            W = W0\n",
    "\n",
    "        if W != W0 or H != H0:\n",
    "            fullimg_pad = np.zeros((H, W, 3), dtype=np.uint16)\n",
    "            fullimg_pad[0:H0, 0:W0] = fullimg.copy()\n",
    "        else:\n",
    "            fullimg_pad = fullimg.copy()\n",
    "\n",
    "        n = 0\n",
    "        raw_detections = np.empty((0, 6))\n",
    "\n",
    "        for x in range(0, W, step):\n",
    "            for y in range(0, H, step):\n",
    "                offset = np.array([x, y, x, y])\n",
    "\n",
    "                # Load image\n",
    "                image = fullimg_pad[y:y + ysize, x:x + xsize]\n",
    "\n",
    "                # Preprocess image for network\n",
    "                image = preprocess_image(image)\n",
    "                image, scale = resize_image(image)\n",
    "\n",
    "                # Process image\n",
    "                boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "\n",
    "                # Correct for image scale\n",
    "                boxes /= scale\n",
    "                boxes += offset\n",
    "                boxes[:, :, 2] = np.clip(boxes[:, :, 2], 0, W0)\n",
    "                boxes[:, :, 3] = np.clip(boxes[:, :, 3], 0, H0)\n",
    "\n",
    "                # Select indices which have a score above the threshold\n",
    "                indices = np.where(scores[0, :] > tHRESHOLD)[0]\n",
    "\n",
    "                # Select those scores\n",
    "                scores = scores[0][indices]\n",
    "\n",
    "                # Find the order with which to sort the scores\n",
    "                scores_sort = np.argsort(-scores)\n",
    "\n",
    "                # Save detections\n",
    "                image_boxes = boxes[0, indices[scores_sort], :]\n",
    "                image_scores = scores[scores_sort]\n",
    "                image_labels = labels[0, indices[scores_sort]]\n",
    "                image_detections = np.concatenate(\n",
    "                    [image_boxes, np.expand_dims(image_scores, axis=1), np.expand_dims(image_labels, axis=1)], axis=1\n",
    "                )\n",
    "                raw_detections = np.append(raw_detections, image_detections, axis=0)\n",
    "    else:\n",
    "        raw_detections = np.empty((0, 6))\n",
    "\n",
    "    # Copy detections to all_detections\n",
    "    for label in range(num_class):\n",
    "        all_detections[i][label] = raw_detections[raw_detections[:, -1] == label, :-1]\n",
    "\n",
    "        # Stitch detections\n",
    "        detections = raw_detections[raw_detections[:, -1] == label, :-1].copy()\n",
    "        if detections.size > 1:\n",
    "            cleaned_detections = stitchDetection(detections, H0, W0, xsize, ysize, step)\n",
    "        else:\n",
    "            cleaned_detections = detections.copy()\n",
    "        cleaned_detections = np.concatenate(\n",
    "            [\n",
    "                cleaned_detections,\n",
    "                np.zeros([cleaned_detections.shape[0], 1]),\n",
    "                np.ones([cleaned_detections.shape[0], 1]) * (i + 1),\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "        clean_detections[i][label] = cleaned_detections\n",
    "\n",
    "        # Visualize detections and output\n",
    "        if cleaned_detections.size > 1:\n",
    "            for j, detection in enumerate(list(cleaned_detections)):\n",
    "                b = list(map(int, detection[:4]))\n",
    "                color = label_color(label)\n",
    "                draw_box(fulldraw, b, color=color, thickness=2)\n",
    "\n",
    "                # Save average intensity of the box area\n",
    "                cleaned_detections[j, 5] = fullimg[b[1]:b[3], b[0]:b[2]].mean()\n",
    "                cv2.imwrite('output' + '_THRE_' + f'{tHRESHOLD:1.1f}' + sUFFIX[cAPTION], fulldraw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f138793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
